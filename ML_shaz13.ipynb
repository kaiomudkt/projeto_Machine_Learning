{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRECISA IMPLEMENTAR CORRETAMENTE ESTE ARQUIVO\n",
    "### https://www.kaggle.com/datasets/shaz13/real-world-documents-collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1569, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ETL_download_dataset_kaggle import download_dataset, unzip_file\n",
    "from ETL_process_image import process_dataset\n",
    "\n",
    "def etl_for_dataframe() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Gerencia o fluxo de download e descompactação do dataset.\n",
    "    Extrai textos das imagens\n",
    "    Prepara textos para serem usado pela ML\n",
    "    \"\"\"\n",
    "    zip_file = 'real-world-documents-collections.zip'\n",
    "    extract_to = 'dataset/real_world_documents_collections'\n",
    "    link_dataset = 'shaz13/real-world-documents-collections'\n",
    "    if not os.path.exists(zip_file):\n",
    "        # Baixar o dataset\n",
    "        download_dataset(link_dataset)\n",
    "        # descompacta arquivo ZIP\n",
    "        unzip_file(zip_file, extract_to)\n",
    "    path_dataset = \"./dataset/real_world_documents_collections/docs-sm\"\n",
    "    path_df_parquet = './DF_shaz13_real_world_documents_collections.parquet'\n",
    "    # TODO:\n",
    "    # required_folders = ['form','resume','letter','invoice', 'questionnaire']\n",
    "    required_folders = ['form']\n",
    "    df = process_dataset(path_dataset, path_df_parquet, required_folders)\n",
    "    return df\n",
    "\n",
    "df = etl_for_dataframe()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>doc_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bellomycarrigginc job university parkway aa ex...</td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inc broadway york screening questionnatre time...</td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alan november account smoking manufacture desc...</td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ob tor old</td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>alpha recognition threshold attribute profile ...</td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bmg</td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>recruitment questionnaire approach year old me...</td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>consumer relation winstonsalem n c frank mayhe...</td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gu verbatim believe main idea brand fro qu qu ...</td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>extended use test please answer following ques...</td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>consensus york ney much core yoy need back boo...</td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>code handed long start_ ever tried step yes ma...</td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>re long interview read parson one</td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bremen institute prevention research social me...</td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>product</td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>extraction</td>\n",
       "      <td>questionnaire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text       doc_type\n",
       "0   bellomycarrigginc job university parkway aa ex...  questionnaire\n",
       "1   inc broadway york screening questionnatre time...  questionnaire\n",
       "2                                                      questionnaire\n",
       "3   alan november account smoking manufacture desc...  questionnaire\n",
       "4                                          ob tor old  questionnaire\n",
       "5                                                      questionnaire\n",
       "6   alpha recognition threshold attribute profile ...  questionnaire\n",
       "7                                                 bmg  questionnaire\n",
       "8   recruitment questionnaire approach year old me...  questionnaire\n",
       "9   consumer relation winstonsalem n c frank mayhe...  questionnaire\n",
       "10  gu verbatim believe main idea brand fro qu qu ...  questionnaire\n",
       "11  extended use test please answer following ques...  questionnaire\n",
       "12  consensus york ney much core yoy need back boo...  questionnaire\n",
       "13  code handed long start_ ever tried step yes ma...  questionnaire\n",
       "14                  re long interview read parson one  questionnaire\n",
       "15  bremen institute prevention research social me...  questionnaire\n",
       "16                                            product  questionnaire\n",
       "17                                                     questionnaire\n",
       "18                                                     questionnaire\n",
       "19                                         extraction  questionnaire"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separando os dados em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vetorizando dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Configurando o TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(ngram_range=(2,5), max_df=0.95, min_df=2 ,max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando e transformando os dados de treinamento\n",
    "tfidf_train = tfidf.fit_transform(X_train)\n",
    "# Convertendo a matriz esparsa em uma matriz densa\n",
    "tfidf_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Lista de modelos para comparar\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajuste de hiperparâmetros usando GridSearchCV\n",
    "\n",
    "busca pela configuração ideal de parâmetros para cada modelo.\n",
    "\n",
    "Definição de param_grids: Para cada modelo, definimos um dicionário de param_grid que contém os parâmetros que desejamos ajustar utilizando GridSearchCV. Os parâmetros específicos foram escolhidos com base na prática comum e podem ser ajustados conforme necessário.\n",
    "\n",
    "Loop de Ajuste de Parâmetros: Iteramos sobre o dicionário models, que contém os modelos a serem testados. Para cada modelo, realizamos o ajuste de hiperparâmetros usando GridSearchCV.\n",
    "\n",
    "GridSearchCV: Criamos um objeto GridSearchCV para cada modelo, onde especificamos o modelo, o param_grid correspondente, o número de folds para validação cruzada (cv=5 neste exemplo) e a métrica de avaliação (scoring='accuracy').\n",
    "\n",
    "Execução da Busca em Grade: Chamamos o método fit() para executar a busca em grade no conjunto de treinamento (tfidf_train, y_train).\n",
    "\n",
    "Armazenamento do Melhor Modelo: Após a busca em grade, armazenamos o melhor modelo encontrado (best_estimator_) no dicionário best_models.\n",
    "\n",
    "Avaliação no Conjunto de Teste: Finalmente, avaliamos os melhores modelos encontrados no conjunto de teste (tfidf_test, y_test) e exibimos a acurácia para cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseado nos melhores parâmetros encontrados\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [2]\n",
    "}\n",
    "\n",
    "param_grid_svc = {\n",
    "    'C': [1.0],\n",
    "    'kernel': ['linear'],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "\n",
    "param_grid_nb = {\n",
    "    'alpha': [0.1],\n",
    "    'fit_prior': [True]\n",
    "}\n",
    "\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [10],\n",
    "    'weights': ['uniform'],\n",
    "    'metric': ['euclidean']\n",
    "}\n",
    "\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [200],\n",
    "    'learning_rate': [0.5],\n",
    "    'max_depth': [10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajustando hiperparâmetros para Logistic Regression ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros encontrados para Logistic Regression:\n",
      "{'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "Ajustando hiperparâmetros para Random Forest ...\n",
      "Melhores parâmetros encontrados para Random Forest:\n",
      "{'max_depth': None, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "\n",
      "Ajustando hiperparâmetros para SVM ...\n",
      "Melhores parâmetros encontrados para SVM:\n",
      "{'C': 1.0, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "\n",
      "Ajustando hiperparâmetros para Naive Bayes ...\n",
      "Melhores parâmetros encontrados para Naive Bayes:\n",
      "{'alpha': 0.1, 'fit_prior': True}\n",
      "\n",
      "Ajustando hiperparâmetros para KNN ...\n",
      "Melhores parâmetros encontrados para KNN:\n",
      "{'metric': 'euclidean', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "\n",
      "Ajustando hiperparâmetros para Gradient Boosting ...\n",
      "Melhores parâmetros encontrados para Gradient Boosting:\n",
      "{'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 200}\n",
      "\n",
      "\n",
      "Avaliação dos melhores modelos no conjunto de teste:\n",
      "Logistic Regression: Acurácia no teste = 0.8182\n",
      "Random Forest: Acurácia no teste = 0.9697\n",
      "SVM: Acurácia no teste = 0.8485\n",
      "Naive Bayes: Acurácia no teste = 0.9394\n",
      "KNN: Acurácia no teste = 0.5455\n",
      "Gradient Boosting: Acurácia no teste = 0.8788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir os primeiros parâmetros para começar a testar em cada modelo\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "param_grid_svc = {\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "param_grid_nb = {\n",
    "    'alpha': [0.1, 0.5, 1.0],\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 10],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.5],\n",
    "    'max_depth': [3, 5, 10]\n",
    "}\n",
    "\n",
    "# Dicionário de param_grids para cada modelo\n",
    "param_grids = {\n",
    "    'Logistic Regression': param_grid_lr,\n",
    "    'Random Forest': param_grid_rf,\n",
    "    'SVM': param_grid_svc,\n",
    "    'Naive Bayes': param_grid_nb,\n",
    "    'KNN': param_grid_knn,\n",
    "    'Gradient Boosting': param_grid_gb\n",
    "}\n",
    "\n",
    "# Lista para armazenar os melhores modelos ajustados\n",
    "best_models = {}\n",
    "\n",
    "# Executar GridSearchCV para cada modelo\n",
    "for name, model in models.items():\n",
    "    print(f\"Ajustando hiperparâmetros para {name} ...\")\n",
    "    # Definir o param_grid específico para o modelo atual\n",
    "    param_grid: dict = param_grids[name]\n",
    "    # Criar o objeto GridSearchCV\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    # Executar a busca em grade no conjunto de treinamento\n",
    "    grid_search.fit(tfidf_train, y_train)    \n",
    "    # Armazenar o melhor modelo ajustado\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    # Mostrar os melhores parâmetros encontrados\n",
    "    print(f\"Melhores parâmetros encontrados para {name}:\")\n",
    "    print(grid_search.best_params_)\n",
    "    print()\n",
    "\n",
    "# Avaliar os melhores modelos no conjunto de teste e mostrar métricas\n",
    "print(\"\\nAvaliação dos melhores modelos no conjunto de teste:\")\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    # Avaliar o modelo no conjunto de teste\n",
    "    accuracy = model.score(tfidf_test, y_test)\n",
    "    print(f'{name}: Acurácia no teste = {accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
